{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "Most neural networks are strictly feed forward, information stricly passes in one direction. Recurrent neural networks allow for each neuron to have a degree of memory. Unlike a feedforward network, in which all inputs are given at the same time to get a given prediction, a recurrent network takes the inputs in sequence. This allows it to have variable input sizes, and for it to remember context from previous entries to determine its final output. This memory is implemented by having a hidden state which acts as an additional input when computing the input sum.\n",
    "\n",
    "These can have many different input-output relationships. One input to one output, one input to many outputs, many inputs to one output, many inputs to many outputs. What about the network determines this relationship? \n",
    "\n",
    "One can use these to form deep networks, and (HOW?) bidirectional recurrent networks, so that the answer in response to each individual input is influenced by terms to either side of it.\n",
    "\n",
    "To train them typically uses a technique called backpropagation through time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try and build a recurrent perceptron before using a tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08832167 0.47754376 0.40095194 0.70201259 0.78310929 0.7239078\n",
      " 0.31295863 0.34847856 0.69853506 0.43467061]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# input weights [x]\n",
    "# activation function\n",
    "# summation function [x]\n",
    "# recurrent input\n",
    "data = np.random.rand(100,10)\n",
    "print(data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4205140315251996, 0.8701747105460453, 0.043348730549622516]\n",
      "[0.68580201 0.46507539 0.96930019 0.67505638 0.57929582 0.669301\n",
      " 0.10857583 0.52730023 0.8546198  0.37807768]\n"
     ]
    }
   ],
   "source": [
    "hidden = 0\n",
    "weights = [np.random.random() for i in range(3)] # weights at index -1 will be bias, weights at -2 will be recurrent\n",
    "\n",
    "# each entry in the data\n",
    "for d in data:\n",
    "    inputs = d\n",
    "    \n",
    "    # iterate through the elements of a data string\n",
    "    for i in inputs:\n",
    "        activation = max(0, weights[0]*i + hidden*weights[1] + weights[2])\n",
    "        # activation = np.log(1+exp(in_sum(inputs, weights, hidden))) # softplus\n",
    "        # acivation = max(0.01*sum(weights[0]*i + hidden*weights[1] + weights[2]), sum(weights[0]*i + hidden*weights[1] + weights[2])) # Leaky relu\n",
    "        hidden = activation\n",
    "\n",
    "print(weights)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, it will make 100 predictions, but it doesn't yet have the ability to learn from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first real RNN, try the Elman network from: https://www.cpuheater.com/deep-learning/introduction-to-recurrent-neural-networks-in-pytorch/\n",
    "\n",
    "This has three layers: a single input neuron, with three recurrent neurons in the hidden layer, and a single output neuron.\n",
    "\n",
    "This uses pytorch for constructing and manipulating the network. It will be used to predict a sine wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some hyperparameters: the network structure, how much to train it, how long a sequence of inputs should be, and the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor\n",
    "input_size = 7\n",
    "hidden_size = 6\n",
    "output_size = 1\n",
    "epochs = 300\n",
    "seq_length = 20\n",
    "lr = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we need to generate training data. In this case, the data is a sine wave. In more practical examples, this would be imported and cleaned data of some kind. What is Variable?\n",
    "\n",
    "linspace generates a list of `seq_length+1` values with equal intervals, starting from `2` and ending at `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.   2.4  2.8  3.2  3.6  4.   4.4  4.8  5.2  5.6  6.   6.4  6.8  7.2\n",
      "  7.6  8.   8.4  8.8  9.2  9.6 10. ]\n"
     ]
    }
   ],
   "source": [
    "data_time_steps = np.linspace(2,10, seq_length+1)\n",
    "print(data_time_steps)\n",
    "data = np.sin(data_time_steps)\n",
    "data.resize((seq_length + 1, 1))\n",
    "\n",
    "x = Variable(torch.Tensor(data[:-1]).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.Tensor(data[1:] ).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create weight matrices both for the input to hidden connection, and for the hidden to output connection. Since these are the parts of the network that will be changing\n",
    "what does init do?\n",
    "why convert to Variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.FloatTensor(input_size, hidden_size).type(dtype)\n",
    "torch.nn.init.normal_(w1, 0.0, 0.4)\n",
    "w1 = Variable(w1, requires_grad=True)\n",
    "\n",
    "w2 = torch.FloatTensor(hidden_size, output_size).type(dtype)\n",
    "torch.nn.init.normal_(w2, 0.0, 0.3)\n",
    "w2 = Variable(w2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context state is a representation of what it has seen so far of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input, context_state, w1, w2):\n",
    "    xh = torch.cat((input, context_state), 1)\n",
    "    context_state = torch.tanh(xh.mm(w1))\n",
    "    out = context_state.mm(w2)\n",
    "    return (out, context_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # what does this do?\n",
    "    context_state = Variable(torch.zeros((1,hidden_size)).type(dtype), requires_grad=True)\n",
    "    \n",
    "    for j in range(x.size(0)):\n",
    "        # get inputs and outputs\n",
    "        input = x[j:(j+1)]\n",
    "        target = y[j:(j+1)]\n",
    "        \n",
    "        # create a prediction, and update the context\n",
    "        (pred, context_state) = forward(input, context_state, w1, w2)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = (pred - target).pow(2).sum()/2\n",
    "        total_loss += loss\n",
    "        loss.backward() # figure out the gradient from the loss back to the weights\n",
    "        \n",
    "        # change the weights for both weight matrices\n",
    "        w1.data -= lr*w1.grad.data\n",
    "        w2.data -= lr*w2.grad.data\n",
    "        \n",
    "        \n",
    "        w1.grad.data.zero_()\n",
    "        w2.grad.data.zero_()\n",
    "        \n",
    "        context_state = Variable(context_state.data)\n",
    "        \n",
    "    #if i%10 == 0:\n",
    "    #    print(f\"Epoch: {i} loss {total_loss.data[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(x[0:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b6eedebdc8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_state = Variable(torch.zeros((1,hidden_size)).type(dtype),requires_grad=False)\n",
    "predictions = []\n",
    "\n",
    "for i in range(x.size(0)):\n",
    "    input = x[i:i+1]\n",
    "    (pred,context_state)=forward(input,context_state, w1, w2)\n",
    "    predictions.append(pred.data.numpy().ravel()[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.linspace(2,10,20), x[0:])\n",
    "plt.scatter(np.linspace(2,10,20), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "Try for an LSTM perceptron?\n",
    "\n",
    "\n",
    "How many weights do I have?\n",
    "what kinds of structures are hidden and cell? scalar? \n",
    "are forget, input output and gate functions or values?\n",
    "how are hidden, weight, and input combined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11601758 0.71481921 0.63170343]\n",
      " [0.09406289 0.53574218 0.95437069]\n",
      " [0.07622232 0.99387198 0.81268108]\n",
      " [0.76948057 0.24984377 0.72087294]]\n",
      "0.8246292510288984\n",
      "3.182920207449984\n"
     ]
    }
   ],
   "source": [
    "hidden = 0\n",
    "cell = 0\n",
    "\n",
    "weights = np.random.rand(4,3)# i(nput) f(orget) o(utput) g(ate)   (bias??), input hidden\n",
    "    \n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "\n",
    "# each entry in the data\n",
    "for d in data:\n",
    "    inputs = d\n",
    "    \n",
    "    # iterate through the elements of a data string\n",
    "    for i in inputs:\n",
    "        inp    = sig(weights[0,0]*i   + weights[0,1]*hidden + weights[0,1]) #?\n",
    "        forget = sig(weights[1,0]*i   + weights[1,1]*hidden + weights[0,1]) #?\n",
    "        output = sig(weights[2,0]*i   + weights[2,1]*hidden + weights[0,1]) #?\n",
    "        gate = np.tanh(weights[2,0]*i + weights[2,1]*hidden + weights[0,1]) #?\n",
    "\n",
    "        cell = forget*cell + inp*gate\n",
    "        hidden = output*np.tanh(cell)\n",
    "\n",
    "print(weights)\n",
    "print(hidden)\n",
    "print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Guide with pytorch\n",
    "https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
