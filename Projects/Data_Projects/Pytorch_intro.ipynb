{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "My notes and introduction to [learning Pytorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), developing a basic convolutional neural net using pytorch methods.\n",
    "First step is to import pytorch, to learn about the tensor class, the grad attribute, and the backward() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding tensors\n",
    "Tensors are basically just $n$-dimensional arrays, with the extra ability to track the changes that are applied to them, and calculate a derivative based on those changes. They do not have to be the same size in each dimension.\n",
    "\n",
    "I set up a simple easy to understand tensor, and set requires_grad to True to more easily understand the effects of backward() and grad.\n",
    "\n",
    "backward can only be applied to non scalar values (still tensors?) if you provide an argument of the same dimensions as the desired output.\n",
    "\n",
    "backward needs to be called before using the grad value, since backward calculates the gradient.\n",
    "\n",
    "In this case, all the values in x.grad sum to 1, which make. This is because calculating the mean requires summing all the values (which are removed when differentiating) and then dividing by the number of values. So for N values i, each value i goes to i/N.\n",
    "\n",
    "If all the values were equal to two, I would expect the sum of the gradient structure to equal 2.\n",
    "\n",
    "If `backward` is run multiple times, there is some kind of compounding effect, until x is redefined and gradients are recalculated. This bears investigating. However, in most uses I don't expect this to be an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.]])\n",
      "tensor([[1.3333, 1.3333, 1.3333]])\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "tensor([[3.3333, 3.3333, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1,3), requires_grad=True) \n",
    "out1=x.sum()\n",
    "out2=x.mean()\n",
    "\n",
    "out1.backward(retain_graph=True)\n",
    "print(x.grad)\n",
    "\n",
    "out2.backward(retain_graph=True) \n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "w=x*2\n",
    "out=w.sum()\n",
    "out.backward() \n",
    "print(w.grad)\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "# running this section repeatedly, continuously changes gradient .1333 -> 0.2 -> 0.26667... unless x is reinitialized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up network class\n",
    "\n",
    "In convolutional neural nets, the input image often has multiple channels (like RGB) which form the intended image only when combined. These can be visualized as three layers of single color images that are overlaid. Therefore, the (ordinarily 2d) filtering kernel needs to be applied separately to each of these channels, giving it an effective depth of the number of channels. From the initial image, one can apply many different kernels at the same time, by introducing  a fourth dimension to the kernel, resulting in many different feature maps. So, the dimensions of the kernel are as follows (unordered): \n",
    "(number of separate feature maps to generate, number of input image channels, 2d size of filter to apply on the input image)\n",
    "\n",
    "From this it is somewhat easier to understand the network class that we are creating. There are two sequential convolution layers. The first takes an image with only one channel, modifies it with a 3x3 filter, and outputs an image with six channels. The second takes an image of 6 channels, and outputs one with 16 channels, again using a 3x3 filter.\n",
    "\n",
    "I'm unsure why `Linear` function is needed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the purpose and function of `Linear`. Each output of the `Linear` function is a linear combination of the inputs, with a bias term. The weights (and bias) can be learned and updated. This is used after the convolution step, so the features have already been found, and now it is deciding what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[-0.0254,  1.1549, -0.1922,  0.1321, -0.4913, -0.0083, -0.7039, -0.3466,\n",
      "          0.3313,  0.5105, -0.1675,  1.2171,  0.3180, -0.0971,  0.0688]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([-0.0254,  1.1549, -0.1922,  0.1321, -0.4913, -0.0083, -0.7039, -0.3466,\n",
      "         0.3313,  0.5105, -0.1675,  1.2171,  0.3180, -0.0971,  0.0688],\n",
      "       grad_fn=<SelectBackward>) tensor([-0.0254,  1.1549, -0.1922,  0.1321, -0.4913, -0.0083, -0.7039, -0.3466,\n",
      "         0.3313,  0.5105, -0.1675,  1.2171,  0.3180, -0.0971,  0.0688],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "a = nn.Linear(10,15) # stretches (or compresses) 10 values to 15\n",
    "# a(10) # throws error\n",
    "b = torch.ones(1,10)\n",
    "print(b)\n",
    "print(a(b))\n",
    "print(min(a(b)), max(a(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grad returns the value of the derivative of the function at the current value of x\n",
    "# confused about what happens when calling backwards() multiple times\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        # call to the init function of the class that Net extends\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        # what are convs used for? why 2?\n",
    "        # one input image channel (?), 6 outputs, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1,6,3)\n",
    "\n",
    "        # (6 input channels, 16 outputs, 3x3 square kernel?)\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "\n",
    "        # what are linears used for? clearly they go in order, why 16*6*6 inputs? why 10 outputs?\n",
    "        # why 3?\n",
    "        self.fc1 = nn.Linear(16*6*6, 120) #576 -> 120\n",
    "        self.fc2 = nn.Linear(120,84) # first here is second from previous # 120->84\n",
    "        self.fc3 = nn.Linear(84, 10) # 84 -> 10\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        what does this do?\n",
    "        what does relu do?\n",
    "        what does max_pool do?\n",
    "        \"\"\"\n",
    "\n",
    "        # convolution step\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "\n",
    "        # reformat x to be useable as typical neural network\n",
    "        x = x.view(-1, self.num_flat_features(x)) # has to be one dimensional for Linear function\n",
    "\n",
    "        # regular neural network behavior, each step is linear combination\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the functions\n",
    "`forward`\n",
    "x is the input, which will be reshaped to a two dimensional tensor by the view function.\n",
    "max_pool2d takes a kernel size, and a step size(tuple is useful for different step size by dimension), a tensor that is 1/(step size) the input, where each entry is the maximum from the original in the pool of the kernel size. It does this separately for each channel.\n",
    "F.relu is an element wise transformation, setting all negative values equal to zero.\n",
    "So, in combination, it takes an input, sets all negatives to zero, and then takes the regional maxima of each channel.\n",
    "\n",
    "`view` rearraneges the data into a new shape, with `-1` meaning to infer the needed shape from what is left over in the other dimesnsions. In this case, it is being reshaped to preserve the first dimension, and combine all the others into a single dimension, so that they can be linearly combined to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([6, 1, 3, 3])\n",
      "shape of input is torch.Size([1, 1, 32, 32])\n",
      "shape of input is torch.Size([1, 16, 6, 6])\n",
      "shape of input is torch.Size([1, 576])\n",
      "tensor([[-0.0416, -0.1104,  0.0316, -0.1033,  0.1010,  0.0539,  0.0441,  0.0650,\n",
      "         -0.1595,  0.0115]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create network\n",
    "net=Net()\n",
    "print(net)\n",
    "\n",
    "# get parameters of the network\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "\n",
    "# random 32x32 input in a 4d tensor (what are 1s for? why 2 extra indices to tensor?)\n",
    "input = torch.randn(1,1,32,32) \n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "# clears all gradient computations (sets to zero)\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We have a network that can make prediction, but it hasn't been able to learn yet, so it's predictions are a very complicated way of choosing randomly. The next step is to train it by giving it feedback from predictions and tests. For this we will need a measure of how wrong a guess is, called a loss function. In this case we use Mean Squared Error, but there are others, which are useful depending on how the target variable is distributed. Gaussian vs binary, with outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8857, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-6.7526e-05,  1.0553e-02, -1.7950e-03,  2.9557e-03,  4.6966e-03,\n",
      "        -3.4039e-03])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will update the weights using stochastic gradient descent. There are many other optimization algorithms. Many are found in the torch.optim module\n",
    "\n",
    "- Gradient descent: take a step proportional to the negative of the gradient, in that direction (very simple)\n",
    "- Stochastic gradient descent: Same as gradient descent, except gradient is approximate, so it's computationally faster\n",
    "- Adaptive Momentum: adds a bit of the previous calculation to the current, giving it effective momentum\n",
    "- Conjugate Gradient: ??? \n",
    "- Quasi Newton Method: Uses an approximation of newton's method\n",
    "- Adadelta/Adagrad: use adaptive learning rates (different methods) on top of SGD\n",
    "- ADAM: combines adaptive learning rates and adaptive momentum\n",
    "- MiniBatch: calculates and combines the gradient for many target values at once before updating model\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(net.parameters)\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Classifier\n",
    "At this point, we are going to build and train a functional classifier, which we will then evaluate. I want to be able to explain all the the decisions that are made, and alternate methods of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform is a composition of two image transformations. The first turns an array into a tensor (simple type compatibility), and the second normalizes each elements means and standard deviations to 0.5.\n",
    "\n",
    "The rest is just fetching data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic examination of the data. Pick a few images at random, and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck truck  frog   dog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the net.\n",
    "We have two convolution steps, and a pooling step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor = my_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size),\n",
    "                         batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Our model\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\"\\tIn Model: input size\", input.size(),\n",
    "              \"output size\", output.size())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in rand_loader:\n",
    "    input = data.to(device)\n",
    "    output = model(input)\n",
    "    print(\"Outside: input size\", input.size(),\n",
    "          \"output_size\", output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
